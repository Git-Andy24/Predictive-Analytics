{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from scikit-learn) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imblearn in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (2.2.1)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /Users/anerudhshyam/Desktop/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('Creditcard_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing dataset and creating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>521</td>\n",
       "      <td>-2.020350</td>\n",
       "      <td>-2.213185</td>\n",
       "      <td>2.208366</td>\n",
       "      <td>1.321452</td>\n",
       "      <td>2.272591</td>\n",
       "      <td>0.465993</td>\n",
       "      <td>-2.137299</td>\n",
       "      <td>0.826641</td>\n",
       "      <td>0.722121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428468</td>\n",
       "      <td>1.117293</td>\n",
       "      <td>0.249403</td>\n",
       "      <td>-0.782377</td>\n",
       "      <td>-0.202575</td>\n",
       "      <td>0.817655</td>\n",
       "      <td>-0.100136</td>\n",
       "      <td>-0.169297</td>\n",
       "      <td>1.404789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>396</td>\n",
       "      <td>-0.652887</td>\n",
       "      <td>0.440189</td>\n",
       "      <td>1.386893</td>\n",
       "      <td>0.164069</td>\n",
       "      <td>0.926974</td>\n",
       "      <td>-0.584341</td>\n",
       "      <td>0.718911</td>\n",
       "      <td>-0.075236</td>\n",
       "      <td>-0.136878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012744</td>\n",
       "      <td>0.099123</td>\n",
       "      <td>-0.145593</td>\n",
       "      <td>-0.095277</td>\n",
       "      <td>-0.098019</td>\n",
       "      <td>-0.308430</td>\n",
       "      <td>-0.012073</td>\n",
       "      <td>-0.027966</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>23</td>\n",
       "      <td>1.204348</td>\n",
       "      <td>0.282818</td>\n",
       "      <td>0.193422</td>\n",
       "      <td>0.496679</td>\n",
       "      <td>-0.025457</td>\n",
       "      <td>-0.278056</td>\n",
       "      <td>-0.046002</td>\n",
       "      <td>0.028063</td>\n",
       "      <td>-0.197863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238021</td>\n",
       "      <td>-0.677104</td>\n",
       "      <td>0.106596</td>\n",
       "      <td>-0.205287</td>\n",
       "      <td>0.176832</td>\n",
       "      <td>0.119716</td>\n",
       "      <td>-0.011830</td>\n",
       "      <td>0.017927</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>484</td>\n",
       "      <td>-2.516005</td>\n",
       "      <td>-2.725340</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>2.092654</td>\n",
       "      <td>1.149148</td>\n",
       "      <td>-1.065149</td>\n",
       "      <td>0.297206</td>\n",
       "      <td>-0.085272</td>\n",
       "      <td>-0.235949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545359</td>\n",
       "      <td>0.281416</td>\n",
       "      <td>1.222866</td>\n",
       "      <td>-0.215686</td>\n",
       "      <td>0.272601</td>\n",
       "      <td>-0.115957</td>\n",
       "      <td>-0.224493</td>\n",
       "      <td>0.035173</td>\n",
       "      <td>464.278122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>516</td>\n",
       "      <td>-1.703881</td>\n",
       "      <td>-1.694988</td>\n",
       "      <td>2.266306</td>\n",
       "      <td>0.875207</td>\n",
       "      <td>2.048267</td>\n",
       "      <td>0.180617</td>\n",
       "      <td>-1.283262</td>\n",
       "      <td>0.526943</td>\n",
       "      <td>0.654253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323942</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.144081</td>\n",
       "      <td>-0.513387</td>\n",
       "      <td>-0.050452</td>\n",
       "      <td>0.497278</td>\n",
       "      <td>-0.119041</td>\n",
       "      <td>-0.158530</td>\n",
       "      <td>1.361682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   521 -2.020350 -2.213185  2.208366  1.321452  2.272591  0.465993   \n",
       "1522   396 -0.652887  0.440189  1.386893  0.164069  0.926974 -0.584341   \n",
       "1523    23  1.204348  0.282818  0.193422  0.496679 -0.025457 -0.278056   \n",
       "1524   484 -2.516005 -2.725340  0.992609  2.092654  1.149148 -1.065149   \n",
       "1525   516 -1.703881 -1.694988  2.266306  0.875207  2.048267  0.180617   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521 -2.137299  0.826641  0.722121  ...  0.428468  1.117293  0.249403   \n",
       "1522  0.718911 -0.075236 -0.136878  ...  0.012744  0.099123 -0.145593   \n",
       "1523 -0.046002  0.028063 -0.197863  ... -0.238021 -0.677104  0.106596   \n",
       "1524  0.297206 -0.085272 -0.235949  ...  0.545359  0.281416  1.222866   \n",
       "1525 -1.283262  0.526943  0.654253  ...  0.323942  0.942544  0.144081   \n",
       "\n",
       "           V24       V25       V26       V27       V28      Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000      0  \n",
       "...        ...       ...       ...       ...       ...         ...    ...  \n",
       "1521 -0.782377 -0.202575  0.817655 -0.100136 -0.169297    1.404789      1  \n",
       "1522 -0.095277 -0.098019 -0.308430 -0.012073 -0.027966    0.997252      1  \n",
       "1523 -0.205287  0.176832  0.119716 -0.011830  0.017927    2.690000      1  \n",
       "1524 -0.215686  0.272601 -0.115957 -0.224493  0.035173  464.278122      1  \n",
       "1525 -0.513387 -0.050452  0.497278 -0.119041 -0.158530    1.361682      1  \n",
       "\n",
       "[1526 rows x 31 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(columns=['Class'])\n",
    "y=df[['Class']]\n",
    "\n",
    "smote=SMOTE()\n",
    "X_sm,y_sm=smote.fit_resample(X,y)\n",
    "\n",
    "sm_df=pd.concat([pd.DataFrame(X_sm),pd.DataFrame(y_sm)],axis=1)\n",
    "sm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing confidence as 95%, Z-score will be: 1.96\n",
    "#margin of error: 5%\n",
    "#proportion: 0.5\n",
    "\n",
    "z=1.96\n",
    "p=0.5 \n",
    "e=0.05\n",
    "N=y_sm.shape[0]\n",
    "\n",
    "sample_size= int((z**2 * p *(1-p))/e**2)\n",
    "sampling_interval= int(N/sample_size)#for systematic sampling\n",
    "\n",
    "str_ls = [] #for stratified sampling\n",
    "for _,group in sm_df.groupby('Class'):\n",
    "    str_ls.append(resample(group,n_samples=int(sample_size/2),random_state=42)) #sample_size/2 gives samples for each group\n",
    "str_samples=pd.concat(str_ls)\n",
    "\n",
    "temp_df=sm_df #for cluster sampling\n",
    "temp_df['Cluster'] = KMeans(n_clusters=5, random_state=42).fit_predict(X_sm)\n",
    "clusters=list(set(temp_df['Cluster']))\n",
    "sampled_clusters=[]\n",
    "\n",
    "for cluster in clusters:\n",
    "    clus_size=len(temp_df[temp_df['Cluster']==cluster])//2\n",
    "    if(clus_size!=0):\n",
    "        sampled_clusters.append(resample(temp_df[temp_df['Cluster']==cluster],replace=False,n_samples=clus_size,random_state=42))\n",
    "\n",
    "sampled_df=pd.concat(sampled_clusters).reset_index(drop=True)\n",
    "sampled_df.drop(columns=['Cluster'])\n",
    "\n",
    "sample_dict={\n",
    "    \"Sampling1\": sm_df.sample(n=sample_size,replace=False,random_state=42),\n",
    "    \"Sampling2\": sm_df.sample(n=sample_size,replace=True,random_state=42), \n",
    "    \"Sampling3\": sm_df.iloc[np.arange(0,N,sampling_interval)[:sample_size]],\n",
    "    \"Sampling4\": str_samples,\n",
    "    \"Sampling5\": sampled_df\n",
    "}\n",
    "\n",
    "type_dict={\n",
    "    \"Sampling1\": \"Simple Random Sampling\",\n",
    "    \"Sampling2\": \"Simple Random Sampling With Replacement\", \n",
    "    \"Sampling3\": \"Systematic Sampling\",\n",
    "    \"Sampling4\": \"Stratified Sampling\",\n",
    "    \"Sampling5\": \"Cluster Sampling\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models and choosing best Sampling for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "models={\n",
    "    \"M1\":RandomForestClassifier(random_state=42),\n",
    "    \"M2\":KNeighborsClassifier(),\n",
    "    \"M3\":SVC(),\n",
    "    \"M4\":KMeans(n_clusters=2,random_state=42),\n",
    "    \"M5\":LogisticRegression(max_iter=10000)\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=[technique for technique, _ in type_dict.items()], index=[\"M1\", \"M2\", \"M3\", \"M4\", \"M5\"])\n",
    "for name,model in models.items():\n",
    "    for technique,sample_df in sample_dict.items():\n",
    "        X_train,X_test,y_train,y_test=train_test_split(sample_df.drop(columns=['Class']), sample_df['Class'], test_size=0.2, random_state=42)\n",
    "        if name==\"M4\":\n",
    "            model.fit(X_train)\n",
    "            y_pred=model.predict(X_test)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred=model.predict(X_test)\n",
    "        results.loc[name,technique]=accuracy_score(y_test,y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Techniques used: \n",
      "Sampling1  -  Simple Random Sampling\n",
      "Sampling2  -  Simple Random Sampling With Replacement\n",
      "Sampling3  -  Systematic Sampling\n",
      "Sampling4  -  Stratified Sampling\n",
      "Sampling5  -  Cluster Sampling\n",
      "\n",
      "Models used: \n",
      "M1  -  RandomForestClassifier(random_state=42)\n",
      "M2  -  KNeighborsClassifier()\n",
      "M3  -  SVC()\n",
      "M4  -  KMeans(n_clusters=2, random_state=42)\n",
      "M5  -  LogisticRegression(max_iter=10000)\n",
      "\n",
      "\n",
      "Sampling Techniques vs Model Accuracy:\n",
      "\n",
      "     Sampling1  Sampling2  Sampling3  Sampling4  Sampling5\n",
      "M1  94.805195      100.0      100.0      100.0   98.69281\n",
      "M2  79.220779  80.519481  76.623377  76.623377  81.699346\n",
      "M3  61.038961  67.532468  76.623377  55.844156  68.627451\n",
      "M4  57.142857   59.74026  36.363636  37.662338  37.908497\n",
      "M5  87.012987  96.103896   89.61039  98.701299  91.503268\n"
     ]
    }
   ],
   "source": [
    "print(\"Sampling Techniques used: \")\n",
    "for key in type_dict.keys():\n",
    "    print(key,\" - \",type_dict[key])\n",
    "\n",
    "print (\"\\nModels used: \")\n",
    "for key in models.keys():\n",
    "    print(key,\" - \",models[key])\n",
    "\n",
    "print(\"\\n\\nSampling Techniques vs Model Accuracy:\")\n",
    "print(\"\\n\",results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models mapped to best sampling techniques with accuracies: \n",
      "\n",
      "M1  -  Accuracy =  100.000 %\n",
      "Sampling Tehniques:  Sampling2, Sampling3, Sampling4\n",
      "M2  -  Accuracy =  81.699 %\n",
      "Sampling Tehniques:  Sampling5\n",
      "M3  -  Accuracy =  76.623 %\n",
      "Sampling Tehniques:  Sampling3\n",
      "M4  -  Accuracy =  59.740 %\n",
      "Sampling Tehniques:  Sampling2\n",
      "M5  -  Accuracy =  98.701 %\n",
      "Sampling Tehniques:  Sampling4\n"
     ]
    }
   ],
   "source": [
    "best_map={}\n",
    "print(\"Models mapped to best sampling techniques with accuracies: \\n\")\n",
    "for model in results.index:\n",
    "    max_accuracy=results.loc[model].max()\n",
    "    ls=list(results.loc[model][results.loc[model]==max_accuracy].index)\n",
    "    best_map[model]=ls\n",
    "    \n",
    "\n",
    "    print(model,\" - \",\"Accuracy = \",format(max_accuracy,\".3f\"),\"%\")\n",
    "    str=\"\"\n",
    "    for ex in ls:\n",
    "        str=str+ex+\", \"\n",
    "    str=str.strip()\n",
    "    str=str[:-1] #remove extra ','\n",
    "    print(\"Sampling Tehniques: \",str)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
